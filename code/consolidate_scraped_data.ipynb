{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidated Scraped Data \n",
    "\n",
    "## Introduction\n",
    "This notebook consolidates data is collected from three sources ([The-Numbers](https://www.the-numbers.com/), [IMDb](https://www.imdb.com/) and [Wikipedia](https://www.wikipedia.org)). Links to notebooks that collect/scrape data from [The-Numbers](the_numbers_scraper.ipynb) and [IMDb](imdb_dataset_download.ipynb) are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, datasets from the two sources are merged using movie title and release year. To do this, spaces and special characters are stripped from the movie titles. \n",
    "\n",
    "For entries that do not match, these additional steps were taken:\n",
    "- Remove _'the'_ and _'and'_ from titles on the unmatched datasets\n",
    "- Match using title and select the nearest year of release (atmost ± 5 years apart)\n",
    "- For The-Numbers dataset with unknown dataset, match only those with single rows after being merged\n",
    "\n",
    "In the next step, movie titles are scraped from Wikipedia for names of the companies that distribute the movies. The final dataframe is also merged with other tables from IMDb datasets using the unique movie id. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, install the wikipedia library (optional)\n",
    "#!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import important libraries \n",
    "import requests \n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the-numbers dataset saved to disk. Run the_numbers_scraper.ipynb first\n",
    "tn_df = pd.read_csv(\"../zippedData/tn_movie_budgets_updated.csv.gz\",compression='gzip')\n",
    "\n",
    "#Create 'startYear' column in tn_df, with similar name to imdb_df\n",
    "tn_df['startYear'] = tn_df['release_date'].map(lambda x: x.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load IMDb dataset. For title matching, title.basics.tsv.gz file is used. Run imdb_dataset_download.ipynb prior to this code\n",
    "imdb_df = pd.read_csv(\"../zippedData/title.basics.tsv.gz\",compression='gzip',delimiter='\\t',low_memory=False)\n",
    "\n",
    "#Select rows with 'titleType' == 'movie'\n",
    "imdb_df = imdb_df[imdb_df['titleType']=='movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set '\\N' values to 'Unknown' (similar to tn_df) and replace numbers in 'startYear' to strings \n",
    "imdb_df[imdb_df['startYear']=='\\\\N']='Unknown'\n",
    "imdb_df['startYear'] = imdb_df['startYear'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign columns to merge on, and columns to choose from imdb_df\n",
    "cols = ['tconst','primaryTitle','originalTitle','isAdult','runtimeMinutes',\n",
    "        'genres','simple_title','startYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function strips away special characters and additional list of strings \n",
    "def prep_title(title, replace=False):\n",
    "    words = ['the','and']\n",
    "    title = [x.lower() for x in title.split()]\n",
    "    if replace:\n",
    "        for word in words:\n",
    "            if word in title:\n",
    "                title.remove(word)\n",
    "    return re.sub('[\\W\\_]','',''.join(title))\n",
    "\n",
    "#Function that returns rows present only in df_1 but not in d_\n",
    "def left_outer_merge(df_1,df_2,column):\n",
    "    left_out = df_1.merge(df_2[column], how=\"left\", on=column,indicator=True)\n",
    "    left_out=left_out[left_out['_merge']=='left_only']\n",
    "    return left_out.drop('_merge',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column named 'simple_title' in 'tn_df' for comparing titles\n",
    "tn_df['simple_title'] = tn_df['movie'].map(lambda x: prep_title(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to merge the two datasets. IMDb dataset has two columns for titles: original and primary. Therefore, titles are prepped from these two columns separately and merged with `tn_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe called movies_df\n",
    "movies_df = pd.DataFrame(columns=list(tn_df.columns)+cols[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that preps the title and concatinates dataframes on orignal and primary titles\n",
    "def concat_with_movies(df_1,df_2,\n",
    "                       merge_cols=['simple_title','startYear'],\n",
    "                       replace=False,\n",
    "                       m_df=pd.DataFrame(),\n",
    "                       cols=cols):\n",
    "    '''\n",
    "    df_1: The first dataframe \n",
    "    df_2: The second dataframe. df_1 and df_2 must share columns \n",
    "          specified by merge_cols\n",
    "    merge_cols: list of columns on which the df_1 and df_2\n",
    "    replace: boolean to replace 'the' and 'and' in the movie titles\n",
    "    m_df: a dummy dataframe returned by the function, set empty by default\n",
    "    cols: columns selected from the df_2\n",
    "    ''' \n",
    "    df_1['simple_title'] = df_1['movie'].map(lambda x: prep_title(x,replace))\n",
    "    for col in df_2.columns:\n",
    "        if 'Title' in col:            \n",
    "            df_2['simple_title'] = df_2[col].map(lambda x: prep_title(x,replace))\n",
    "            df = pd.merge(df_1,df_2[cols],on=merge_cols)\n",
    "            if m_df.empty:\n",
    "                m_df =df\n",
    "            else:\n",
    "                m_df = pd.concat([m_df,df[m_df.columns]])\n",
    "    return m_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First merge tn_df and imdb_df based on title and release year\n",
    "movies_df = concat_with_movies(tn_df,imdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find unmerged rows\n",
    "un_merged_1 = left_outer_merge(tn_df,movies_df,'simple_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'the','and' on the unmerged rows and try again\n",
    "movies_df = pd.concat([movies_df,concat_with_movies(un_merged_1,imdb_df,replace=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find missing rows\n",
    "un_merged_2 = left_outer_merge(tn_df,movies_df,'simple_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to merge `un_merged_2` using titles and check if the release years in `tn_df` and `imdb_df` are within 5 years of each other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that returns string of years ± 5 years in 'un_merged_2' dataframe\n",
    "def list_year(year,gap):\n",
    "    try:\n",
    "        return ','.join([str(int(year)+i) for i in range(-gap,gap+1)])\n",
    "    except:\n",
    "        return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge un_merged_2 and imdb_df on title alone first with replacements \n",
    "empty_df = pd.DataFrame(columns=list(tn_df.columns)+cols)\n",
    "mer_2_titl = concat_with_movies(un_merged_2,imdb_df,\n",
    "                                    replace=True,\n",
    "                                    merge_cols='simple_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mer_2_titl` has two `startYear` columns. We now apply `list_year` function to `startYear_x` column and check if `startYear_y` is in `startYear_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of years ± 2 years in 'startYear_x'\n",
    "gap = 3\n",
    "mer_2_titl['startYear_x'] = mer_2_titl['startYear_x'].apply(lambda x: list_year(x,gap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select values 'startYear_y' that are in 'startYear_x' and store them in column called 'isin'\n",
    "mer_2_titl['isin'] = [x[0] in x[1] for x in zip(mer_2_titl['startYear_y'],mer_2_titl['startYear_x'])]\n",
    "mer_2_titl = mer_2_titl[mer_2_titl['isin']]\n",
    "\n",
    "#Select all columns except 'startYear_x' and 'isin'\n",
    "mer_2_titl.drop(['startYear_x','isin'],axis=1,inplace=True)\n",
    "\n",
    "#Rename startYear_y to simply startYear\n",
    "mer_2_titl.rename(columns = {'startYear_y':'startYear'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the effort, however, it's possible that one title might be merged with multiple titles from `imdb_df`. Therefore, simply groupinig the table based on `id` and then taking the first entry is going to solve this issue.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the first in grouped rows by id and then reset the index\n",
    "mer_2_titl = mer_2_titl.groupby('id').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `mer_2_titl` can be concatenated with `movies_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contactenate mer_2_titl and movies_df\n",
    "movies_df = pd.concat([movies_df,mer_2_titl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we match the titles with unknown release data in `tn_df` with `imdb_df` that do not appear in `movies_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select titles with unknown 'startYear' that are not movies_df\n",
    "year_unk_df = left_outer_merge(tn_df[tn_df['startYear']=='Unknown'],movies_df,'simple_title')\n",
    "\n",
    "#Merge 'year_unk_df' and 'imdb_df' on title alone\n",
    "unk_merge = concat_with_movies(year_unk_df,imdb_df,\n",
    "                               replace=True,\n",
    "                               merge_cols='simple_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to earlier, `unk_merge` will have `startYear_x` and `startYear_y`columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop 'startYear_x' and rename 'startYear_y' to 'startYear'\n",
    "unk_merge.drop('startYear_x',axis=1, inplace=True)\n",
    "unk_merge.rename(columns = {'startYear_y':'startYear'}, inplace = True)\n",
    "\n",
    "#Take the first in grouped rows by id and then reset the index as a precaution\n",
    "unk_merge = unk_merge.groupby('id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge unk_merge with movies_df\n",
    "movies_df = pd.concat([movies_df,unk_merge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last effort, we are going to merge the remaining dataset in `tn_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the titles that are not merged yet. \n",
    "remaining_df = left_outer_merge(tn_df,movies_df,'movie')\n",
    "name_only = concat_with_movies(remaining_df,imdb_df,\n",
    "                                  replace=True,\n",
    "                                  merge_cols='simple_title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the remaining titles, the nearest values of `startYear_y` to `startYear_x` were chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the unique ids to be iterated\n",
    "unique_ids = name_only['id'].unique()\n",
    "\n",
    "#Cast years to int\n",
    "name_only[['startYear_x','startYear_y']] = name_only[['startYear_x','startYear_y']].astype(int)\n",
    "\n",
    "#Loop through each unique id, collect df with similar id, \n",
    "#find the closest year by subtracting startYear_x from startYear_y\n",
    "# and keep the closest value\n",
    "df = name_only.copy()\n",
    "for id_ in unique_ids:\n",
    "    tmp = name_only[name_only['id']==id_]\n",
    "    df_idx = tmp.index.tolist() \n",
    "    #Calculated to differences from 'startYear_x'\n",
    "    diff = [abs(i-j) for i,j in zip(tmp['startYear_x'],tmp['startYear_y'])]\n",
    "    idx = df_idx[diff.index(min(diff))]\n",
    "    df_idx.remove(idx)\n",
    "    df.drop(df_idx,axis=0,inplace=True)    \n",
    "name_only = df\n",
    "\n",
    "#Change the years back to str\n",
    "name_only[['startYear_x','startYear_y']] = name_only[['startYear_x','startYear_y']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop 'startYear_x' and rename 'startYear_y' to 'startYear'\n",
    "name_only.drop('startYear_x',axis=1, inplace=True)\n",
    "name_only.rename(columns = {'startYear_y':'startYear'}, inplace = True)\n",
    "\n",
    "#Take the first in grouped rows by id and then reset the index as a precaution\n",
    "name_only = name_only.groupby('id').first().reset_index()\n",
    "\n",
    "#Merge name_only with movies_df\n",
    "movies_df = pd.concat([movies_df,name_only])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, as a precaution, we have to group `movies_df` by `id`, reset the index and take the first value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.groupby('tconst').first().reset_index()\n",
    "\n",
    "#Remove 'simple_title' column\n",
    "movies_df.drop('simple_title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 titles were discarded.\n"
     ]
    }
   ],
   "source": [
    "discarded_df = left_outer_merge(tn_df,movies_df,'movie')\n",
    "print('{} titles were discarded.'.format(len(discarded_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "160 movies out of 6183 is not bad. We will now proceed to merging the `movies_df` with `title.crew.tsv.gz`,`title.principals.tsv.gz`, `title.ratings.tsv.gz` and `name.basics.tsv.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time constraint and constantly maxing out requests, Wikipedia scraper was not implemented. The idea was to search for each movie title using the `wikipedia` library like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#This code scrapes the distributor of movies in movies_df. \n",
    "#Multiple requests can result in time out. \n",
    "wiki = 'https://en.wikipedia.org/wiki/'\n",
    "movies_df['distributedBy'] = ''\n",
    "for i,movie in movies_df[52:].iterrows():\n",
    "    results = wikipedia.search(movie['movie']+' film '+movie['startYear'])\n",
    "    try:\n",
    "        # Instead of making two requests, wikipedia's page.html() \n",
    "        # is attempted first\n",
    "        page = wikipedia.page(results[0]).html()\n",
    "        soup = BeautifulSoup(page,'html.parser')\n",
    "    except:\n",
    "        url = wiki+results[0]\n",
    "        html_page = requests.get(url,timeout=5)\n",
    "        soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "    movies_df.loc[i,'distributedBy'] = distributed_filler(soup)\n",
    "\n",
    "\n",
    "#Find the word 'Distributed by' in 'infobox vevent' table\n",
    "def distributed_filler(soup):\n",
    "    '''\n",
    "    soup is BeautifulSoup object parsing a Wikipedia html page\n",
    "    The function looks up tags in the'infobox vevent' table\n",
    "    by looping through 'th' elements. If 'Distributed by' \n",
    "    found, the index is used to extract distributer company \n",
    "    name from 'td' element. \n",
    "    '''\n",
    "    distrib = 'Unknown'\n",
    "    info_table = soup.find('table',class_='infobox vevent')        \n",
    "    if info_table!=None:            \n",
    "        col_names = []\n",
    "        for info in info_table.find_all('th'):\n",
    "            col_names.append(info.get_text(strip=True))\n",
    "            if 'Distributed by' in col_names:\n",
    "                col_vals = info_table.find_all('td')\n",
    "                idx = col_names.index('Distributed by')\n",
    "                distrib = col_vals[idx].get_text(strip=True)\n",
    "    return distrib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging movies dataframe more information from IMDb\n",
    "Now that `movies_df` is ready, the remaining dataset can be loaded and joined using `tconst` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add rating \n",
    "rating_df = pd.read_csv(\"../zippedData/title.ratings.tsv.gz\",compression='gzip',delimiter='\\t',low_memory=False)\n",
    "movies_df = pd.merge(movies_df,rating_df,on='tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add principals for each movie \n",
    "princ_df = pd.read_csv(\"../zippedData/title.principals.tsv.gz\",compression='gzip',delimiter='\\t')\n",
    "princ_df = pd.merge(princ_df[['tconst','nconst','category']],movies_df['tconst'],on='tconst')\n",
    "princ_df.drop_duplicates(inplace=True)\n",
    "\n",
    "#Find names. We only need names that are in the movies. So assigning the merged dataframe is assigned to itself\n",
    "names = pd.read_csv(\"../zippedData/name.basics.tsv.gz\",compression='gzip',delimiter='\\t')\n",
    "names = pd.merge(names[['nconst','primaryName']],princ_df['nconst'],on='nconst')\n",
    "names.drop_duplicates(inplace=True)\n",
    "\n",
    "#Merge principals and names\n",
    "princ_df = pd.merge(princ_df,names,on='nconst')\n",
    "princ_df.drop('nconst',axis=1,inplace=True)\n",
    "\n",
    "#Pivot table by 'tconst' and 'category'\n",
    "pv_prin_df = princ_df.groupby(['tconst','category'])['primaryName'].apply(list)\n",
    "pv_prin_df = pv_prin_df.reset_index()\n",
    "pv_prin_df = pv_prin_df.pivot(index='tconst', columns='category', values='primaryName')\n",
    "pv_prin_df = pv_prin_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our table has list of directors, writers, actor and so on, we need to stretch each role and append that to `movies_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each columns in 'pv_prin_df', stretch that to multiple columns,\n",
    "# change the column names and append that to 'movies_df'\n",
    "new_cols = list(pv_prin_df.columns)\n",
    "roles = pd.DataFrame()\n",
    "for col in new_cols:\n",
    "    df = pv_prin_df[col].apply(pd.Series)\n",
    "    df.columns = [col+'_'+str(int(i)+1) for i in df.columns]\n",
    "    if roles.empty:\n",
    "        roles = df\n",
    "    else:\n",
    "        roles = pd.concat([roles,df],axis=1)\n",
    "\n",
    "#Before merging to 'movies_df', the code above appends '_1' to 'tconst'. The column must be renamed \n",
    "roles.rename(columns = {'tconst_1':'tconst'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, 'movies_df' and roles can be merged using 'tconst'\n",
    "movies_df = pd.merge(movies_df,roles,on='tconst')\n",
    "\n",
    "#It is important to avoid repeated rows therefore we need to get rid of those first \n",
    "movies_df = movies_df.groupby('tconst').first().reset_index()\n",
    "movies_df = movies_df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save movies_df to file\n",
    "movies_df.to_csv(\"../zippedData/movies.csv.gz\",compression='gzip', encoding='utf-8',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we were able to successfully merge to distinct datasets based on the information provided. This required a lot of massaging the data to make sure that every movie is matched with its equivalent information provided. The [next notebook](visualization.ipynb) shows step-by-step code on how to generate important plots for decision making. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
